
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../imgs/Favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.3.3">
    
    
      
        <title>Accuracy Calculation - PyTorch Metric Learning</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.4a0965b7.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#ef5552">
        
      
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="red" data-md-color-accent="red">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#accuracy-calculation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="PyTorch Metric Learning" class="md-header__button md-logo" aria-label="PyTorch Metric Learning" data-md-component="logo">
      
  <img src="../imgs/TinyLogo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            PyTorch Metric Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Accuracy Calculation
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/KevinMusgrave/pytorch-metric-learning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    KevinMusgrave/pytorch-metric-learning
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="PyTorch Metric Learning" class="md-nav__button md-logo" aria-label="PyTorch Metric Learning" data-md-component="logo">
      
  <img src="../imgs/TinyLogo.png" alt="logo">

    </a>
    PyTorch Metric Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/KevinMusgrave/pytorch-metric-learning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    KevinMusgrave/pytorch-metric-learning
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../distances/" class="md-nav__link">
        Distances
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../losses/" class="md-nav__link">
        Losses
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../miners/" class="md-nav__link">
        Miners
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../reducers/" class="md-nav__link">
        Reducers
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../regularizers/" class="md-nav__link">
        Regularizers
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../samplers/" class="md-nav__link">
        Samplers
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../trainers/" class="md-nav__link">
        Trainers
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../testers/" class="md-nav__link">
        Testers
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_10" type="checkbox" id="__nav_10" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_10">
          Utils
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Utils" data-md-level="1">
        <label class="md-nav__title" for="__nav_10">
          <span class="md-nav__icon md-icon"></span>
          Utils
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Accuracy Calculation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Accuracy Calculation
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#getting-accuracy" class="md-nav__link">
    Getting accuracy
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lone-query-labels" class="md-nav__link">
    Lone query labels
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cpugpu-usage" class="md-nav__link">
    CPU/GPU usage
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#explanations-of-the-default-accuracy-metrics" class="md-nav__link">
    Explanations of the default accuracy metrics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adding-custom-accuracy-metrics" class="md-nav__link">
    Adding custom accuracy metrics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-a-custom-label-comparison-function" class="md-nav__link">
    Using a custom label comparison function
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../inference_models/" class="md-nav__link">
        Inference Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../logging_presets/" class="md-nav__link">
        Logging Presets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../common_functions/" class="md-nav__link">
        Common Functions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../distributed/" class="md-nav__link">
        Distributed
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_11" type="checkbox" id="__nav_11" >
      
      
      
      
        <label class="md-nav__link" for="__nav_11">
          How to extend this library
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="How to extend this library" data-md-level="1">
        <label class="md-nav__title" for="__nav_11">
          <span class="md-nav__icon md-icon"></span>
          How to extend this library
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extend/losses/" class="md-nav__link">
        Custom losses
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extend/miners/" class="md-nav__link">
        Custom miners
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../faq/" class="md-nav__link">
        Frequently Asked Questions
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#getting-accuracy" class="md-nav__link">
    Getting accuracy
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lone-query-labels" class="md-nav__link">
    Lone query labels
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cpugpu-usage" class="md-nav__link">
    CPU/GPU usage
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#explanations-of-the-default-accuracy-metrics" class="md-nav__link">
    Explanations of the default accuracy metrics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adding-custom-accuracy-metrics" class="md-nav__link">
    Adding custom accuracy metrics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-a-custom-label-comparison-function" class="md-nav__link">
    Using a custom label comparison function
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/KevinMusgrave/pytorch-metric-learning/edit/master/docs/accuracy_calculation.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



<h1 id="accuracy-calculation">Accuracy Calculation<a class="headerlink" href="#accuracy-calculation" title="Permanent link">&para;</a></h1>
<p>The AccuracyCalculator class computes several accuracy metrics given a query and reference embeddings. It can be easily extended to create custom accuracy metrics.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_metric_learning.utils.accuracy_calculator</span> <span class="kn">import</span> <span class="n">AccuracyCalculator</span>
<span class="n">AccuracyCalculator</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">(),</span>
                    <span class="n">exclude</span><span class="o">=</span><span class="p">(),</span>
                    <span class="n">avg_of_avgs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">return_per_class</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">label_comparison_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">knn_func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">kmeans_func</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<h3 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>include</strong>: Optional. A list or tuple of strings, which are the names of metrics you want to calculate. If left empty, all default metrics will be calculated.</li>
<li><strong>exclude</strong>: Optional. A list or tuple of strings, which are the names of metrics you <strong>do not</strong> want to calculate.</li>
<li><strong>avg_of_avgs</strong>: If True, the average accuracy per class is computed, and then the average of those averages is returned. This can be useful if your dataset has unbalanced classes. If False, the global average will be returned.</li>
<li><strong>return_per_class</strong>: If True, the average accuracy per class is computed and returned.</li>
<li><strong>k</strong>: The number of nearest neighbors that will be retrieved for metrics that require k-nearest neighbors. The allowed values are:<ul>
<li><code>None</code>. This means k will be set to the total number of reference embeddings.</li>
<li>An integer greater than 0. This means k will be set to the input integer.</li>
<li><code>"max_bin_count"</code>. This means k will be set to <code>max(bincount(reference_labels)) - self_count</code> where <code>self_count == 1</code> if the query and reference embeddings come from the same source.</li>
</ul>
</li>
<li><strong>label_comparison_fn</strong>: A function that compares two torch arrays of labels and returns a boolean array. The default is <code>torch.eq</code>. If a custom function is used, then you must exclude clustering based metrics ("NMI" and "AMI"). The example below shows a custom function for two-dimensional labels. It returns <code>True</code> if the 0th column matches, and the 1st column does <strong>not</strong> match.</li>
<li><strong>device</strong>: The device to move input tensors to. If <code>None</code>, will default to GPUs if available.</li>
<li><strong>knn_func</strong>: A callable that takes in 4 arguments (<code>query, k, reference, ref_includes_query</code>) and returns <code>distances, indices</code>. Default is <code>pytorch_metric_learning.utils.inference.FaissKNN</code>.</li>
<li><strong>kmeans_func</strong>: A callable that takes in 2 arguments (<code>x, nmb_clusters</code>) and returns a 1-d tensor of cluster assignments. Default is <code>pytorch_metric_learning.utils.inference.FaissKMeans</code>.
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_metric_learning.distances</span> <span class="kn">import</span> <span class="n">SNRDistance</span>
<span class="kn">from</span> <span class="nn">pytorch_metric_learning.utils.inference</span> <span class="kn">import</span> <span class="n">CustomKNN</span>

<span class="k">def</span> <span class="nf">example_label_comparison_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">knn_func</span> <span class="o">=</span> <span class="n">CustomKNN</span><span class="p">(</span><span class="n">SNRDistance</span><span class="p">())</span>
<span class="n">AccuracyCalculator</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;NMI&quot;</span><span class="p">,</span> <span class="s2">&quot;AMI&quot;</span><span class="p">),</span> 
                    <span class="n">label_comparison_fn</span><span class="o">=</span><span class="n">example_label_comparison_fn</span><span class="p">,</span>
                    <span class="n">knn_func</span><span class="o">=</span><span class="n">knn_func</span><span class="p">)</span>
</code></pre></div></li>
</ul>
<h3 id="getting-accuracy">Getting accuracy<a class="headerlink" href="#getting-accuracy" title="Permanent link">&para;</a></h3>
<p>Call the <code>get_accuracy</code> method to obtain a dictionary of accuracies.
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
    <span class="n">query</span><span class="p">,</span>
    <span class="n">query_labels</span><span class="p">,</span>       
    <span class="n">reference</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
    <span class="n">ref_includes_query</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">include</span><span class="o">=</span><span class="p">(),</span>
    <span class="n">exclude</span><span class="o">=</span><span class="p">()</span>
<span class="p">):</span>
<span class="c1"># returns a dictionary mapping from metric names to accuracy values</span>
<span class="c1"># The default metrics are:</span>
<span class="c1"># &quot;NMI&quot; (Normalized Mutual Information)</span>
<span class="c1"># &quot;AMI&quot; (Adjusted Mutual Information)</span>
<span class="c1"># &quot;precision_at_1&quot;</span>
<span class="c1"># &quot;r_precision&quot;</span>
<span class="c1"># &quot;mean_average_precision_at_r&quot;</span>
</code></pre></div></p>
<ul>
<li><strong>query</strong>: A 2D torch or numpy array of size <code>(Nq, D)</code>, where Nq is the number of query samples. For each query sample, nearest neighbors are retrieved and accuracy is computed.</li>
<li><strong>query_labels</strong>: A 1D torch or numpy array of size <code>(Nq)</code>. Each element should be an integer representing the sample's label.</li>
<li><strong>reference</strong>: A 2D torch or numpy array of size <code>(Nr, D)</code>, where Nr is the number of reference samples. This is where nearest neighbors are retrieved from.</li>
<li><strong>reference_labels</strong>: A 1D torch or numpy array of size <code>(Nr)</code>. Each element should be an integer representing the sample's label. </li>
<li><strong>ref_includes_query</strong>: Set to True if <code>query</code> is a subset of <code>reference</code> or if <code>query is reference</code>. Set to False otherwise.</li>
<li><strong>include</strong>: Optional. A list or tuple of strings, which are the names of metrics you want to calculate. If left empty, all metrics specified during initialization will be calculated.</li>
<li><strong>exclude</strong>: Optional. A list or tuple of strings, which are the names of metrics you do not want to calculate.</li>
</ul>
<p>Note that labels can be 2D if a <a href="#using-a-custom-label-comparison-function">custom label comparison function</a> is used.</p>
<h3 id="lone-query-labels">Lone query labels<a class="headerlink" href="#lone-query-labels" title="Permanent link">&para;</a></h3>
<p>If some query labels don't appear in the reference set, then it's impossible for those labels to have non-zero k-nn accuracy. Zero accuracy for these labels doesn't indicate anything about the quality of the embedding space. So these lone query labels are excluded from k-nn based accuracy calculations.</p>
<p>For example, if the input <code>query_labels</code> is <code>[0,0,1,1]</code> and <code>reference_labels</code> is <code>[1,1,1,2,2]</code>, then 0 is considered a lone query label.</p>
<h3 id="cpugpu-usage">CPU/GPU usage<a class="headerlink" href="#cpugpu-usage" title="Permanent link">&para;</a></h3>
<ul>
<li>If you installed <code>faiss-cpu</code> then the CPU will always be used.</li>
<li>If you installed <code>faiss-gpu</code>, then the GPU will be used if <code>k &lt;= 1024</code> for CUDA &lt; 9.5, and <code>k &lt;= 2048</code> for CUDA &gt;= 9.5. If this condition is not met, then the CPU will be used. </li>
</ul>
<p>If your dataset is large, you might find the k-nn search is very slow. This is because the default behavior is to set k to <code>len(reference_embeddings)</code>. To avoid this, you can set k to a number, like <code>k = 1000</code>, or try <code>k = "max_bin_count"</code>.</p>
<h3 id="explanations-of-the-default-accuracy-metrics">Explanations of the default accuracy metrics<a class="headerlink" href="#explanations-of-the-default-accuracy-metrics" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>AMI</strong>: </p>
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html">scikit-learn article</a></li>
<li><a href="https://en.wikipedia.org/wiki/Adjusted_mutual_information">Wikipedia</a></li>
</ul>
</li>
<li>
<p><strong>NMI</strong>:</p>
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html">scikit-learn article</a></li>
<li><a href="https://course.ccs.neu.edu/cs6140sp15/7_locality_cluster/Assignment-6/NMI.pdf">Slides from Northeastern University</a></li>
</ul>
</li>
<li>
<p><strong>mean_average_precision</strong>:</p>
<ul>
<li><a href="https://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-1-per.pdf">Slides from Stanford</a></li>
</ul>
</li>
<li>
<p><strong>mean_average_precision_at_r</strong>:</p>
<ul>
<li><a href="https://arxiv.org/pdf/2003.08505.pdf">See section 3.2 of A Metric Learning Reality Check</a></li>
</ul>
</li>
<li>
<p><strong>mean_reciprocal_rank</strong>:</p>
<ul>
<li><a href="https://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-1-per.pdf">Slides from Stanford</a></li>
</ul>
</li>
<li>
<p><strong>precision_at_1</strong>:</p>
<ul>
<li>Fancy way of saying "is the 1st nearest neighbor correct?"</li>
</ul>
</li>
<li>
<p><strong>r_precision</strong>:</p>
<ul>
<li><a href="https://nlp.stanford.edu/IR-book/">See chapter 8 (page 161) of Introduction to Information Retrieval</a></li>
</ul>
</li>
</ul>
<p><strong>Important note</strong></p>
<p>AccuracyCalculator's <code>mean_average_precision_at_r</code> and <code>r_precision</code> are correct only if <code>k = None</code>, <strong>or</strong> <code>k = "max_bin_count"</code>, <strong>or</strong> <code>k &gt;= max(bincount(reference_labels))</code></p>
<h3 id="adding-custom-accuracy-metrics">Adding custom accuracy metrics<a class="headerlink" href="#adding-custom-accuracy-metrics" title="Permanent link">&para;</a></h3>
<p>Let's say you want to use the existing metrics but also compute precision @ 2, and a fancy mutual info method. You can extend the existing class, and write methods that start with the keyword <code>calculate_</code></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_metric_learning.utils</span> <span class="kn">import</span> <span class="n">accuracy_calculator</span>

<span class="k">class</span> <span class="nc">YourCalculator</span><span class="p">(</span><span class="n">accuracy_calculator</span><span class="o">.</span><span class="n">AccuracyCalculator</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">calculate_precision_at_2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">knn_labels</span><span class="p">,</span> <span class="n">query_labels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">accuracy_calculator</span><span class="o">.</span><span class="n">precision_at_k</span><span class="p">(</span><span class="n">knn_labels</span><span class="p">,</span> <span class="n">query_labels</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">calculate_fancy_mutual_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query_labels</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">fancy_computations</span>

    <span class="k">def</span> <span class="nf">requires_clustering</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">requires_clustering</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;fancy_mutual_info&quot;</span><span class="p">]</span> 

    <span class="k">def</span> <span class="nf">requires_knn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">requires_knn</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;precision_at_2&quot;</span><span class="p">]</span> 
</code></pre></div>
<p>Any method that starts with "calculate_" will be passed the following kwargs:
<div class="highlight"><pre><span></span><code><span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">query</span><span class="p">,</span>                    <span class="c1"># query embeddings</span>
    <span class="s2">&quot;reference&quot;</span><span class="p">:</span> <span class="n">reference</span><span class="p">,</span>                  <span class="c1"># reference embeddings</span>
    <span class="s2">&quot;query_labels&quot;</span><span class="p">:</span> <span class="n">query_labels</span><span class="p">,</span>        
    <span class="s2">&quot;reference_labels&quot;</span><span class="p">:</span> <span class="n">reference_labels</span><span class="p">,</span>
    <span class="s2">&quot;ref_includes_query&quot;</span><span class="p">:</span> <span class="n">e</span><span class="p">}</span>  <span class="c1"># True if query is reference, or if query is a subset of reference.</span>
</code></pre></div></p>
<p>If your method requires a k-nearest neighbors search, then append your method's name to the <code>requires_knn</code> list, as shown in the above example. If any of your accuracy methods require k-nearest neighbors, they will also receive the following kwargs:</p>
<div class="highlight"><pre><span></span><code>    <span class="p">{</span><span class="s2">&quot;label_counts&quot;</span><span class="p">:</span> <span class="n">label_counts</span><span class="p">,</span>           <span class="c1"># A dictionary mapping from reference labels to the number of times they occur</span>
    <span class="s2">&quot;knn_labels&quot;</span><span class="p">:</span> <span class="n">knn_labels</span><span class="p">,</span>                <span class="c1"># A 2d array where each row is the labels of the nearest neighbors of each query. The neighbors are retrieved from the reference set</span>
    <span class="s2">&quot;knn_distances&quot;</span><span class="p">:</span> <span class="n">knn_distances</span>           <span class="c1"># The euclidean distance corresponding to each k-nearest neighbor in knn_labels</span>
    <span class="s2">&quot;lone_query_labels&quot;</span><span class="p">:</span> <span class="n">lone_query_labels</span>   <span class="c1"># The set of labels (in the form of a torch array) that have only 1 occurrence in reference_labels</span>
    <span class="s2">&quot;not_lone_query_mask&quot;</span><span class="p">:</span> <span class="n">not_lone_query_mask</span><span class="p">}</span> <span class="c1"># A boolean mask, where True means that a query element has at least 1 possible neighbor in reference.           </span>
</code></pre></div>
<p>If your method requires cluster labels, then append your method's name to the <code>requires_clustering</code> list, as shown in the above example. Then, if any of your methods need cluster labels, <code>self.get_cluster_labels()</code> will be called, and the kwargs will include:</p>
<div class="highlight"><pre><span></span><code>    <span class="p">{</span><span class="s2">&quot;cluster_labels&quot;</span><span class="p">:</span> <span class="n">cluster_labels</span><span class="p">}</span> <span class="c1"># A 1D array with a cluster label for each element in the query embeddings.</span>
</code></pre></div>
<p>Now when <code>get_accuracy</code> is called, the returned dictionary will contain <code>precision_at_2</code> and <code>fancy_mutual_info</code>:
<div class="highlight"><pre><span></span><code><span class="n">calculator</span> <span class="o">=</span> <span class="n">YourCalculator</span><span class="p">()</span>
<span class="n">acc_dict</span> <span class="o">=</span> <span class="n">calculator</span><span class="o">.</span><span class="n">get_accuracy</span><span class="p">(</span><span class="n">query_embeddings</span><span class="p">,</span>
    <span class="n">query_labels</span><span class="p">,</span>
    <span class="n">reference_embeddings</span><span class="p">,</span>
    <span class="n">reference_labels</span><span class="p">,</span>
    <span class="n">ref_includes_query</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="c1"># Now acc_dict contains the metrics &quot;precision_at_2&quot; and &quot;fancy_mutual_info&quot;</span>
<span class="c1"># in addition to the original metrics from AccuracyCalculator</span>
</code></pre></div></p>
<p>You can use your custom calculator with the <a href="../testers/">tester</a> classes as well, by passing it in as an init argument. (By default, the testers use AccuracyCalculator.)
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">testers</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">testers</span><span class="o">.</span><span class="n">GlobalEmbeddingSpaceTester</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">accuracy_calculator</span><span class="o">=</span><span class="n">YourCalculator</span><span class="p">())</span>
</code></pre></div></p>
<h3 id="using-a-custom-label-comparison-function">Using a custom label comparison function<a class="headerlink" href="#using-a-custom-label-comparison-function" title="Permanent link">&para;</a></h3>
<p>If you define your own <code>label_comparison_fn</code>, then <code>query_labels</code> and <code>reference_labels</code> can be 1D or 2D, and consist of integers or floating point numbers, as long as your <code>label_comparison_fn</code> can process them.</p>
<p>Example of 2D labels:
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">label_comparison_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># these are valid labels</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
<span class="p">])</span>
</code></pre></div></p>
<p>Example of floating point labels:
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">label_comparison_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span>

<span class="c1"># these are valid labels</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="mf">10.0</span><span class="p">,</span>
    <span class="mf">0.03</span><span class="p">,</span>
    <span class="mf">0.04</span><span class="p">,</span>
    <span class="mf">0.05</span><span class="p">,</span>
<span class="p">])</span>
</code></pre></div></p>

              
            </article>
            
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../testers/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Testers" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Testers
            </div>
          </div>
        </a>
      
      
        
        <a href="../inference_models/" class="md-footer__link md-footer__link--next" aria-label="Next: Inference Models" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Inference Models
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b028fd86.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.f758a944.min.js"></script>
      
    
  </body>
</html>
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f72op35szD9r"
   },
   "source": [
    "**Authored by [Will Connell](https://twitter.com/wilstc)**\n",
    "\n",
    "**Published 04/23/2020**\n",
    "\n",
    "**[Keiser Laboratory](https://www.keiserlab.org/), UCSF**\n",
    "\n",
    "**Find the Pytorch Metric Learning library [documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/) & [GitHub](https://github.com/KevinMusgrave/pytorch-metric-learning/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKpRHvy24tV7"
   },
   "source": [
    "## Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ZeIGxbbp3W2S",
    "outputId": "e3a1c920-6330-4d0f-910b-56fe14705393"
   },
   "outputs": [],
   "source": [
    "!pip install -q pytorch-metric-learning[with-hooks]\n",
    "!pip install -q scanpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfqRRbIw4zYR"
   },
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "567qnmi7wk_M",
    "outputId": "c42a1636-78af-4994-d178-da79940f9b4c"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import logging\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import record_keeper\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pytorch_metric_learning\n",
    "import pytorch_metric_learning.utils.logging_presets as logging_presets\n",
    "\n",
    "# Main\n",
    "from pytorch_metric_learning import losses, miners, samplers, testers, trainers\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (8.7, 6.27)})\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats(\"retina\")\n",
    "\n",
    "# Logs\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info(\"VERSION %s\" % pytorch_metric_learning.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qxs6EEeR496q"
   },
   "source": [
    "## Models and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKyR6gnTwk_P"
   },
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    # Useful code from fast.ai tabular model\n",
    "    # https://github.com/fastai/fastai/blob/3b7c453cfa3845c6ffc496dd4043c07f3919270e/fastai/tabular/models.py#L6\n",
    "    def __init__(self, in_sz, out_sz, emb_szs, ps, use_bn=True, actn=nn.ReLU()):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.in_sz = in_sz\n",
    "        self.out_sz = out_sz\n",
    "        self.n_embs = len(emb_szs) - 1\n",
    "        if ps == 0:\n",
    "            ps = np.zeros(self.n_embs)\n",
    "        # input layer\n",
    "        layers = [nn.Linear(self.in_sz, emb_szs[0]), actn]\n",
    "        # hidden layers\n",
    "        for i in range(self.n_embs):\n",
    "            layers += self.bn_drop_lin(\n",
    "                n_in=emb_szs[i], n_out=emb_szs[i + 1], bn=use_bn, p=ps[i], actn=actn\n",
    "            )\n",
    "        # output layer\n",
    "        layers.append(nn.Linear(emb_szs[-1], self.out_sz))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "\n",
    "    def bn_drop_lin(\n",
    "        self,\n",
    "        n_in: int,\n",
    "        n_out: int,\n",
    "        bn: bool = True,\n",
    "        p: float = 0.0,\n",
    "        actn: nn.Module = None,\n",
    "    ):\n",
    "        # https://github.com/fastai/fastai/blob/3b7c453cfa3845c6ffc496dd4043c07f3919270e/fastai/layers.py#L44\n",
    "        \"Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn`.\"\n",
    "        layers = [nn.BatchNorm1d(n_in)] if bn else []\n",
    "        if p != 0:\n",
    "            layers.append(nn.Dropout(p))\n",
    "        layers.append(nn.Linear(n_in, n_out))\n",
    "        if actn is not None:\n",
    "            layers.append(actn)\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "# This will be used to create train and val sets\n",
    "class BasicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf0xgdWS5GqG"
   },
   "source": [
    "## Create the dataset and train/val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "1fff675cdf3d4c968256b312ec56413d",
      "89b258373c7a4fdaba6cff888adddf00",
      "8625e3b4d2884715a260184178a9342d",
      "866beafeac674d9aaaf7c69a292688ee",
      "39972264af1d466e81a72c321ee523c2",
      "99906f85754f461cabbf0be755413e84",
      "06a780246e9e44f1bf4391faae9bb7d8",
      "e2182f89534d4f1dbf6bec87c00678b7"
     ]
    },
    "colab_type": "code",
    "id": "kJ0vtgSkxWrZ",
    "outputId": "8e298387-387c-4ccc-8121-f8604b3f5bdc"
   },
   "outputs": [],
   "source": [
    "# get data and format\n",
    "adata = sc.datasets.paul15()\n",
    "# can try preprocessing here...\n",
    "# sc.pp.recipe_zheng17(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SuxPISRf9wAE"
   },
   "source": [
    "This dataset is from a 2015 *Cell* paper titled: [\"Transcriptional Heterogeneity and Lineage Commitment in Myeloid Progenitors\"](https://www.cell.com/cell/fulltext/S0092-8674(15)01493-2?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867415014932%3Fshowall%3Dtrue).\n",
    "\n",
    "We will use cell type clusters that the authors were able to define through canonical marker genes to train and validate embeddings. Then, we will project remaining clusters into the metric space. From the publication:\n",
    "\n",
    "\n",
    "\n",
    "> \"We found that, while some of the single-cell clusters (e.g. C1–C6, C14–C15, C16–C17) \n",
    "form groups that express marker genes corresponding to erythrocyte, monocyte, and neutrophil progenitors, \n",
    "other clusters (C7–C13) showed specific and distinct progenitor expression distributions that were not \n",
    "aligned with a simple hierarchical model of the population\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "6xyLOMC-KVg1",
    "outputId": "4e901d9e-923a-4f3b-c0ab-5ed4c616ab8a"
   },
   "outputs": [],
   "source": [
    "# create dictionary of label map\n",
    "label_map = dict(enumerate(adata.obs[\"paul15_clusters\"].cat.categories))\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8Jnht6-xqjj"
   },
   "outputs": [],
   "source": [
    "# extract of some of the most representative clusters for training/testing\n",
    "clusters = [0, 1, 2, 3, 4, 5, 13, 14, 15, 16]\n",
    "indices = adata.obs[\"paul15_clusters\"].cat.codes.isin(clusters)\n",
    "data, labels = adata.X[indices], adata.obs[indices][\"paul15_clusters\"].cat.codes.values\n",
    "\n",
    "# extract holdout clusters for projection\n",
    "hld_data, hld_labels = (\n",
    "    adata.X[~indices],\n",
    "    adata.obs[~indices][\"paul15_clusters\"].cat.codes.values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHks4Qhe0Pa3"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data, labels, stratify=labels, test_size=0.2, random_state=77\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btjxk6zR5Cl6"
   },
   "source": [
    "## Initialize datasets, models, and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tzmyFS3wk_R"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training, validation, holdout set\n",
    "train_dataset = BasicDataset(X_train, y_train)\n",
    "val_dataset = BasicDataset(X_val, y_val)\n",
    "hld_dataset = BasicDataset(hld_data, hld_labels)\n",
    "\n",
    "# Set embedder model. This takes in the output of the trunk and outputs 64 dimensional embeddings\n",
    "model = EmbeddingNet(\n",
    "    in_sz=len(adata.var),\n",
    "    out_sz=25,\n",
    "    emb_szs=[1000, 500, 250, 100],\n",
    "    ps=0,\n",
    "    use_bn=False,\n",
    "    actn=nn.ReLU(),\n",
    ")\n",
    "model = nn.DataParallel(model).to(device)\n",
    "\n",
    "# Set optimizers\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7J817Vs5LNs"
   },
   "source": [
    "##Create the loss, miner, sampler, and package them into dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kp9AC_4Dwk_V",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the loss function\n",
    "loss = losses.TripletMarginLoss(margin=0.1)\n",
    "\n",
    "# Set the mining function\n",
    "miner = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "# Set the dataloader sampler\n",
    "sampler = samplers.MPerClassSampler(\n",
    "    y_train.flatten(), m=4, length_before_new_iter=len(train_dataset)\n",
    ")\n",
    "\n",
    "# Set other training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "# Package the above stuff into dictionaries.\n",
    "models = {\"trunk\": model}\n",
    "optimizers = {\"trunk_optimizer\": model_optimizer}\n",
    "loss_funcs = {\"metric_loss\": loss}\n",
    "mining_funcs = {\"tuple_miner\": miner}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A9fa1VYD5Yv0"
   },
   "source": [
    "## Create the training and testing hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UUmNLPLFLd-Z"
   },
   "outputs": [],
   "source": [
    "# Remove logs if you want to train with new parameters\n",
    "!rm -rf example_logs/ example_saved_models/ example_tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vq_Pd7Pd5Xi_"
   },
   "outputs": [],
   "source": [
    "record_keeper, _, _ = logging_presets.get_record_keeper(\n",
    "    \"example_logs\", \"example_tensorboard\"\n",
    ")\n",
    "hooks = logging_presets.get_hook_container(record_keeper)\n",
    "dataset_dict = {\"train\": train_dataset, \"val\": val_dataset}\n",
    "model_folder = \"example_saved_models\"\n",
    "\n",
    "# Create the tester\n",
    "tester = testers.GlobalEmbeddingSpaceTester(\n",
    "    end_of_testing_hook=hooks.end_of_testing_hook,\n",
    "    dataloader_num_workers=2,\n",
    "    use_trunk_output=True,\n",
    ")\n",
    "\n",
    "end_of_epoch_hook = hooks.end_of_epoch_hook(\n",
    "    tester, dataset_dict, model_folder, test_interval=1, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0D3Jvxc5iWD"
   },
   "source": [
    "## Create the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DuASrVs-wk_X",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = trainers.MetricLossOnly(\n",
    "    models,\n",
    "    optimizers,\n",
    "    batch_size,\n",
    "    loss_funcs,\n",
    "    mining_funcs,\n",
    "    train_dataset,\n",
    "    sampler=sampler,\n",
    "    dataloader_num_workers=2,\n",
    "    end_of_iteration_hook=hooks.end_of_iteration_hook,\n",
    "    end_of_epoch_hook=end_of_epoch_hook,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gIq7s7jf5ksj"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WHza2JJHwk_Z",
    "outputId": "e13d704e-8b03-4ae1-cfb3-301dca3d2049"
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PEbolviIdgM"
   },
   "source": [
    "## Evaluate Loss and Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "m-rDDn6lIm6w",
    "outputId": "61edaecd-ea80-402b-ebbb-ed608b90379f"
   },
   "outputs": [],
   "source": [
    "loss_history = hooks.get_loss_history()\n",
    "plt.plot(loss_history[\"metric_loss\"], \"r\", alpha=0.5, label=\"loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "WNIqh_JdIxlY",
    "outputId": "e4a8c2ab-e7a6-4e10-a751-f9a2b1ddb264"
   },
   "outputs": [],
   "source": [
    "for c, ds in zip([\"r\", \"b\"], [\"train\", \"val\"]):\n",
    "    accuracies = hooks.get_accuracy_history(tester, ds, return_all_metrics=True)\n",
    "    plt.plot(accuracies[\"epoch\"], accuracies[\"AMI_level0\"], \"{}x-\".format(c), label=ds)\n",
    "plt.legend()\n",
    "plt.title(\"Adjusted Mutual Info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fH9Wj6P6IRlU"
   },
   "source": [
    "## Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gMZVLm2FDD2H",
    "outputId": "71632495-6cb6-41cb-f231-0943a6bb5a4c"
   },
   "outputs": [],
   "source": [
    "# extract embeddings\n",
    "train_emb, train_lab = tester.get_all_embeddings(\n",
    "    train_dataset, model, return_as_numpy=True\n",
    ")\n",
    "val_emb, val_lab = tester.get_all_embeddings(val_dataset, model, return_as_numpy=True)\n",
    "hld_emb, hld_lab = tester.get_all_embeddings(hld_dataset, model, return_as_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xg84AkZO3B0x"
   },
   "outputs": [],
   "source": [
    "# Visualize embeddings using tSNE\n",
    "# combine validation and holdout embeddings\n",
    "comb_emb = np.concatenate((train_emb, val_emb))\n",
    "comb_lab = np.concatenate((train_dataset.labels, val_dataset.labels))\n",
    "comb_src = np.concatenate(\n",
    "    (np.repeat(\"TRAIN\", len(train_emb)), np.repeat(\"VAL\", len(val_emb)))\n",
    ")\n",
    "\n",
    "comb_tsne = TSNE().fit_transform(comb_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "colab_type": "code",
    "id": "l-RpjzTHo467",
    "outputId": "47bfff99-413c-4076-fdf9-3b1bbee42885"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=comb_tsne[:, 0], y=comb_tsne[:, 1], hue=comb_src)\n",
    "plt.title(\"Training & Val Embeddings tSNE\")\n",
    "plt.show()\n",
    "sns.scatterplot(\n",
    "    x=comb_tsne[:, 0],\n",
    "    y=comb_tsne[:, 1],\n",
    "    hue=[label_map[i] for i in comb_lab],\n",
    "    style=comb_src,\n",
    "    palette=\"Paired\",\n",
    ")\n",
    "plt.title(\"Training & Val Embeddings tSNE\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haVrekTr8NNq"
   },
   "source": [
    "## Project Holdout Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PS3El_7p4oMW"
   },
   "outputs": [],
   "source": [
    "# combine validation and holdout embeddings\n",
    "comb_hld_emb = np.concatenate((comb_emb, hld_emb))\n",
    "comb_hld_lab = np.concatenate((comb_lab, hld_labels))\n",
    "comb_hld_src = np.concatenate((comb_src, np.repeat(\"HLD\", len(hld_emb))))\n",
    "\n",
    "comb_hld_tsne = TSNE().fit_transform(comb_hld_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "colab_type": "code",
    "id": "aT_a7GkpHh2t",
    "outputId": "0b435594-21ca-4305-fdd4-ad7b2111c363"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=comb_hld_tsne[:, 0], y=comb_hld_tsne[:, 1], hue=comb_hld_src)\n",
    "plt.title(\"Combined Embeddings tSNE\")\n",
    "plt.show()\n",
    "sns.scatterplot(\n",
    "    x=comb_hld_tsne[:, 0],\n",
    "    y=comb_hld_tsne[:, 1],\n",
    "    hue=[label_map[i] for i in comb_hld_lab],\n",
    "    hue_order=label_map.values(),\n",
    "    style=comb_hld_src,\n",
    "    palette=\"Paired\",\n",
    ")\n",
    "plt.title(\"Combined Embeddings tSNE\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYObZzpNyDrD"
   },
   "source": [
    "## Score Cells in Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GyZ8TS4sNPp"
   },
   "outputs": [],
   "source": [
    "# avergage embedding (prototypical) location of training clusters\n",
    "comb_df = pd.DataFrame(comb_emb, comb_lab)\n",
    "proto = comb_df.groupby(comb_df.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ic3O2FlrrqDe"
   },
   "outputs": [],
   "source": [
    "# distances of holdout embeddings to cluster centers\n",
    "sim = pairwise_distances(hld_emb, proto.values)\n",
    "sim_df = pd.DataFrame(\n",
    "    sim, [label_map[i] for i in hld_labels], [label_map[i] for i in proto.index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "id": "zlRADJferyz_",
    "outputId": "e52a0751-265b-4593-e719-cd16f8bf9014"
   },
   "outputs": [],
   "source": [
    "# hierarchical clustering of relative location\n",
    "sns.clustermap(sim_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "scRNAseq_MetricEmbedding.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06a780246e9e44f1bf4391faae9bb7d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fff675cdf3d4c968256b312ec56413d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8625e3b4d2884715a260184178a9342d",
       "IPY_MODEL_866beafeac674d9aaaf7c69a292688ee"
      ],
      "layout": "IPY_MODEL_89b258373c7a4fdaba6cff888adddf00"
     }
    },
    "39972264af1d466e81a72c321ee523c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8625e3b4d2884715a260184178a9342d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "paul15.h5: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99906f85754f461cabbf0be755413e84",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39972264af1d466e81a72c321ee523c2",
      "value": 1
     }
    },
    "866beafeac674d9aaaf7c69a292688ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2182f89534d4f1dbf6bec87c00678b7",
      "placeholder": "​",
      "style": "IPY_MODEL_06a780246e9e44f1bf4391faae9bb7d8",
      "value": " 10.3M/? [00:07&lt;00:00, 1.36MB/s]"
     }
    },
    "89b258373c7a4fdaba6cff888adddf00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99906f85754f461cabbf0be755413e84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2182f89534d4f1dbf6bec87c00678b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
        <link rel="next" href="distances/">
      
      
      <link rel="icon" href="imgs/Favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.1">
    
    
      
        <title>PyTorch Metric Learning</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.45e1311d.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pytorch-metric-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="." title="PyTorch Metric Learning" class="md-header__button md-logo" aria-label="PyTorch Metric Learning" data-md-component="logo">
      
  <img src="imgs/TinyLogo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            PyTorch Metric Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Home
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/KevinMusgrave/pytorch-metric-learning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    KevinMusgrave/pytorch-metric-learning
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="." title="PyTorch Metric Learning" class="md-nav__button md-logo" aria-label="PyTorch Metric Learning" data-md-component="logo">
      
  <img src="imgs/TinyLogo.png" alt="logo">

    </a>
    PyTorch Metric Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/KevinMusgrave/pytorch-metric-learning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    KevinMusgrave/pytorch-metric-learning
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Home
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="." class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#google-colab-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Google Colab Examples
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-loss-functions-work" class="md-nav__link">
    <span class="md-ellipsis">
      How loss functions work
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How loss functions work">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-losses-and-miners-in-your-training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Using losses and miners in your training loop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#customizing-loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Customizing loss functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-loss-functions-for-unsupervised-self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Using loss functions for unsupervised / self-supervised learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#highlights-of-the-rest-of-the-library" class="md-nav__link">
    <span class="md-ellipsis">
      Highlights of the rest of the library
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#required-pytorch-version" class="md-nav__link">
    <span class="md-ellipsis">
      Required PyTorch version
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pip" class="md-nav__link">
    <span class="md-ellipsis">
      Pip
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conda" class="md-nav__link">
    <span class="md-ellipsis">
      Conda
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="distances/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distances
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="losses/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Losses
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="miners/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Miners
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="reducers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reducers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="regularizers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Regularizers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="samplers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Samplers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="trainers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trainers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="testers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Testers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            Utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="accuracy_calculation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accuracy Calculation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="inference_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="logging_presets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Logging Presets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="common_functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Common Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="distributed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    How to extend this library
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            How to extend this library
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="extend/losses/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom losses
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="extend/miners/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom miners
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Frequently Asked Questions
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#google-colab-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Google Colab Examples
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-loss-functions-work" class="md-nav__link">
    <span class="md-ellipsis">
      How loss functions work
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How loss functions work">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-losses-and-miners-in-your-training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Using losses and miners in your training loop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#customizing-loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Customizing loss functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-loss-functions-for-unsupervised-self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Using loss functions for unsupervised / self-supervised learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#highlights-of-the-rest-of-the-library" class="md-nav__link">
    <span class="md-ellipsis">
      Highlights of the rest of the library
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#required-pytorch-version" class="md-nav__link">
    <span class="md-ellipsis">
      Required PyTorch version
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pip" class="md-nav__link">
    <span class="md-ellipsis">
      Pip
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conda" class="md-nav__link">
    <span class="md-ellipsis">
      Conda
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="pytorch-metric-learning">PyTorch Metric Learning<a class="headerlink" href="#pytorch-metric-learning" title="Permanent link">&para;</a></h1>
<h2 id="google-colab-examples">Google Colab Examples<a class="headerlink" href="#google-colab-examples" title="Permanent link">&para;</a></h2>
<p>See the <a href="https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/README.md">examples folder</a> for notebooks you can download or run on Google Colab.</p>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>This library contains 9 modules, each of which can be used independently within your existing codebase, or combined together for a complete train/test workflow.</p>
<p><img alt="high_level_module_overview" src="imgs/high_level_module_overview.png" /></p>
<h2 id="how-loss-functions-work">How loss functions work<a class="headerlink" href="#how-loss-functions-work" title="Permanent link">&para;</a></h2>
<h3 id="using-losses-and-miners-in-your-training-loop">Using losses and miners in your training loop<a class="headerlink" href="#using-losses-and-miners-in-your-training-loop" title="Permanent link">&para;</a></h3>
<p>Let’s initialize a plain <a href="losses/#tripletmarginloss">TripletMarginLoss</a>:
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">losses</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">TripletMarginLoss</span><span class="p">()</span>
</code></pre></div></p>
<p>To compute the loss in your training loop, pass in the embeddings computed by your model, and the corresponding labels. The embeddings should have size (N, embedding_size), and the labels should have size (N), where N is the batch size.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># your training loop</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>
<p>The TripletMarginLoss computes all possible triplets within the batch, based on the labels you pass into it. Anchor-positive pairs are formed by embeddings that share the same label, and anchor-negative pairs are formed by embeddings that have different labels. </p>
<p>Sometimes it can help to add a mining function:
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">miners</span><span class="p">,</span> <span class="n">losses</span>
<span class="n">miner</span> <span class="o">=</span> <span class="n">miners</span><span class="o">.</span><span class="n">MultiSimilarityMiner</span><span class="p">()</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">TripletMarginLoss</span><span class="p">()</span>

<span class="c1"># your training loop</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">hard_pairs</span> <span class="o">=</span> <span class="n">miner</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">hard_pairs</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>
In the above code, the miner finds positive and negative pairs that it thinks are particularly difficult. Note that even though the TripletMarginLoss operates on triplets, it’s still possible to pass in pairs. This is because the library automatically converts pairs to triplets and triplets to pairs, when necessary.</p>
<h3 id="customizing-loss-functions">Customizing loss functions<a class="headerlink" href="#customizing-loss-functions" title="Permanent link">&para;</a></h3>
<p>Loss functions can be customized using <a href="distances/">distances</a>, <a href="reducers/">reducers</a>, and <a href="regularizers/">regularizers</a>. In the diagram below, a miner finds the indices of hard pairs within a batch. These are used to index into the distance matrix, computed by the distance object. For this diagram, the loss function is pair-based, so it computes a loss per pair. In addition, a regularizer has been supplied, so a regularization loss is computed for each embedding in the batch. The per-pair and per-element losses are passed to the reducer, which (in this diagram) only keeps losses with a high value. The averages are computed for the high-valued pair and element losses, and are then added together to obtain the final loss.</p>
<p><img alt="high_level_loss_function_overview" src="imgs/high_level_loss_function_overview.png" /></p>
<p>Now here's an example of a customized TripletMarginLoss:
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_metric_learning.distances</span> <span class="kn">import</span> <span class="n">CosineSimilarity</span>
<span class="kn">from</span> <span class="nn">pytorch_metric_learning.reducers</span> <span class="kn">import</span> <span class="n">ThresholdReducer</span>
<span class="kn">from</span> <span class="nn">pytorch_metric_learning.regularizers</span> <span class="kn">import</span> <span class="n">LpRegularizer</span>
<span class="kn">from</span> <span class="nn">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">losses</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">TripletMarginLoss</span><span class="p">(</span><span class="n">distance</span> <span class="o">=</span> <span class="n">CosineSimilarity</span><span class="p">(),</span> 
                                    <span class="n">reducer</span> <span class="o">=</span> <span class="n">ThresholdReducer</span><span class="p">(</span><span class="n">high</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span> 
                                    <span class="n">embedding_regularizer</span> <span class="o">=</span> <span class="n">LpRegularizer</span><span class="p">())</span>
</code></pre></div>
This customized triplet loss has the following properties:</p>
<ul>
<li>The loss will be computed using cosine similarity instead of Euclidean distance.</li>
<li>All triplet losses that are higher than 0.3 will be discarded.</li>
<li>The embeddings will be L2 regularized.  </li>
</ul>
<h3 id="using-loss-functions-for-unsupervised-self-supervised-learning">Using loss functions for unsupervised / self-supervised learning<a class="headerlink" href="#using-loss-functions-for-unsupervised-self-supervised-learning" title="Permanent link">&para;</a></h3>
<p>A <code>SelfSupervisedLoss</code> wrapper is provided for self-supervised learning:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_metric_learning.losses</span> <span class="kn">import</span> <span class="n">SelfSupervisedLoss</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">SelfSupervisedLoss</span><span class="p">(</span><span class="n">TripletMarginLoss</span><span class="p">())</span>

<span class="c1"># your training for-loop</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">your_model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">augmented</span> <span class="o">=</span> <span class="n">your_model</span><span class="p">(</span><span class="n">your_augmentation</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">augmented</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>
<p>If you're interested in <a href="https://arxiv.org/pdf/1911.05722.pdf">MoCo</a>-style self-supervision, take a look at the <a href="https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/examples#simple-examples">MoCo on CIFAR10</a> notebook. It uses CrossBatchMemory to implement the momentum encoder queue, which means you can use any tuple loss, and any tuple miner to extract hard samples from the queue.</p>
<h2 id="highlights-of-the-rest-of-the-library">Highlights of the rest of the library<a class="headerlink" href="#highlights-of-the-rest-of-the-library" title="Permanent link">&para;</a></h2>
<ul>
<li>For a convenient way to train your model, take a look at the <a href="trainers">trainers</a>.</li>
<li>Want to test your model's accuracy on a dataset? Try the <a href="testers/">testers</a>.</li>
<li>To compute the accuracy of an embedding space directly, use <a href="accuracy_calculation/">AccuracyCalculator</a>.</li>
</ul>
<p>If you're short of time and want a complete train/test workflow, check out the <a href="https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/examples">example Google Colab notebooks</a>.</p>
<h2 id="installation">Installation<a class="headerlink" href="#installation" title="Permanent link">&para;</a></h2>
<h3 id="required-pytorch-version">Required PyTorch version<a class="headerlink" href="#required-pytorch-version" title="Permanent link">&para;</a></h3>
<ul>
<li><code>pytorch-metric-learning &gt;= v0.9.90</code> requires <code>torch &gt;= 1.6</code></li>
<li><code>pytorch-metric-learning &lt; v0.9.90</code> doesn't have a version requirement, but was tested with <code>torch &gt;= 1.2</code></li>
</ul>
<h3 id="pip">Pip<a class="headerlink" href="#pip" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>pip install pytorch-metric-learning
</code></pre></div>
<p><strong>To get the latest dev version</strong>:
<div class="highlight"><pre><span></span><code>pip install pytorch-metric-learning --pre
</code></pre></div></p>
<p><strong>To install on Windows</strong>:
<div class="highlight"><pre><span></span><code>pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html
pip install pytorch-metric-learning
</code></pre></div></p>
<p><strong>To install with evaluation and logging capabilities (This will install the unofficial pypi version of faiss-gpu)</strong>:
<div class="highlight"><pre><span></span><code>pip install pytorch-metric-learning[with-hooks]
</code></pre></div></p>
<p><strong>To install with evaluation and logging capabilities (CPU) (This will install the unofficial pypi version of faiss-cpu)</strong>:
<div class="highlight"><pre><span></span><code>pip install pytorch-metric-learning[with-hooks-cpu]
</code></pre></div></p>
<h3 id="conda">Conda<a class="headerlink" href="#conda" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>conda install -c conda-forge pytorch-metric-learning
</code></pre></div>
<p><strong>To use the testing module, you'll need faiss, which can be installed via conda as well. See the <a href="https://github.com/facebookresearch/faiss/blob/master/INSTALL.md">installation instructions for faiss</a>.</strong></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": ".", "features": [], "search": "assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.d7c377c4.min.js"></script>
      
    
  </body>
</html>